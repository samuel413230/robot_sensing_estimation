{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import time \n",
    "\n",
    "def tic():\n",
    "    return time.time()\n",
    "\n",
    "def toc(tstart, nm=\"\"):\n",
    "    print('%s took: %s sec.\\n' % (nm,(time.time() - tstart)))\n",
    "\n",
    "def read_data(fname):\n",
    "    d = []\n",
    "    with open(fname, 'rb') as f:\n",
    "        if sys.version_info[0] < 3:\n",
    "            d = pickle.load(f)\n",
    "        else:\n",
    "            d = pickle.load(f, encoding='latin1')  # need for python 3\n",
    "    return d\n",
    "\n",
    "# Sensor Calibration\n",
    "def calibrateSensor(imud):\n",
    "    import numpy as np\n",
    "    sensitivity_gyro = 3.33*180/np.pi\n",
    "    sensitivity_acc = 300\n",
    "\n",
    "    gyro_scale = 3300/1023/sensitivity_gyro\n",
    "    acc_scale = 3300/1023/sensitivity_acc\n",
    "\n",
    "    # calculate the bias for imu data\n",
    "    BIAS_SAMPLE = 100\n",
    "\n",
    "    bias = np.mean(imud['vals'][:,:BIAS_SAMPLE], axis = 1)\n",
    "    \n",
    "    imud['vals'] = imud['vals'] - bias.reshape(6,1)\n",
    "\n",
    "    # scale acc and gyro data\n",
    "    imud['vals'][:3,:] = imud['vals'][:3,:]*acc_scale\n",
    "    imud['vals'][3:,:] = imud['vals'][3:,:]*gyro_scale\n",
    "\n",
    "    # flip Ax and Ay\n",
    "    imud['vals'][:2,:] = -1*imud['vals'][:2,:]\n",
    "\n",
    "    # Swap WzWxWy to WxWyWz\n",
    "    temp = imud['vals'][3,:].copy()\n",
    "    imud['vals'][3,:] = imud['vals'][4,:]\n",
    "    imud['vals'][4,:] = imud['vals'][5,:]\n",
    "    imud['vals'][5,:] = temp\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import library for conversion functions\n",
    "from transformations import *\n",
    "from transformations import euler_from_quaternion, quaternion_matrix\n",
    "# euler_from_matrix, euler_matrix, quaternion_from_euler, euler_from_quaternion, quaternion_matrix\n",
    "\n",
    "# Quaternion functions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vector2hatmap(w):\n",
    "    return np.array([[0, -w[2], w[1]],[w[2], 0, -w[0]],[-w[1], w[0], 0]])\n",
    "\n",
    "def hatmap2vector(W):\n",
    "    \"\"\"\n",
    "    param W: 3x3 hat map\n",
    "    return: vector constructed from the hat map, numpy 1D-array\n",
    "    \"\"\"\n",
    "    assert W.shape == (3,3)\n",
    "    return np.array(W[2,1],W[0,2],W[1,0])\n",
    "\n",
    "def Rot2Quat(w):\n",
    "    zeta = w/np.linalg.norm(w)\n",
    "    theta = np.linalg.norm(w)\n",
    "    \n",
    "    return np.append(np.cos(theta/2),np.sin(theta/2)*zeta)\n",
    "\n",
    "def Quat2Rot(q):\n",
    "    theta = 2*np.arccos(q[0])\n",
    "    \n",
    "    if theta:\n",
    "        return theta*q[1:]/np.sin(theta/2)\n",
    "    else:\n",
    "        return np.zeros(len(q)-1)\n",
    "    \n",
    "def Quat_Conj(q):\n",
    "    return np.append(q[0],-q[1:])\n",
    "\n",
    "def Quat_Multiply(q,p):\n",
    "    qs = q[0]\n",
    "    ps = p[0]\n",
    "    qv = q[1:]\n",
    "    pv = p[1:]\n",
    "    return np.append(qs*ps - np.dot(qv.T,pv), qs*pv + ps*qv + np.cross(qv,pv))\n",
    "\n",
    "def Quat_MultiplyTwo(q,p):\n",
    "    p0 = p[0]*q[0] - p[1]*q[1] - p[2]*q[2] - p[3]*q[3]\n",
    "    p1 = p[0]*q[1] + p[1]*q[0] - p[2]*q[3] + p[3]*q[2]\n",
    "    p2 = p[0]*q[2] + p[1]*q[3] + p[2]*q[0] - p[3]*q[1]\n",
    "    p3 = p[0]*q[3] - p[1]*q[2] + p[2]*q[1] + p[3]*q[0]\n",
    "    \n",
    "    return np.array([p0,p1,p2,p3])\n",
    "\n",
    "def Quat_Inv(q):\n",
    "    return Quat_Conj(q)/(np.linalg.norm(q)**2)\n",
    "\n",
    "def Quat_exp(q):\n",
    "    \n",
    "    qs = q[0]\n",
    "    qv = q[1:]\n",
    "\n",
    "    tol = 1e-17\n",
    "    qv_n = np.linalg.norm(q[1:])\n",
    "    if qv_n > tol:\n",
    "        return np.exp(qs)*np.append(np.cos(qv_n), np.sin(qv_n)*qv/qv_n)\n",
    "    else:\n",
    "        return np.exp(qs)*np.append(np.cos(qv_n), np.sin(qv_n)*qv)\n",
    "\n",
    "def Quat_log(q):\n",
    "    \n",
    "    qs = q[0]\n",
    "    qv = q[1:]\n",
    "    qv_n = np.linalg.norm(q[1:])\n",
    "    q_n = np.linalg.norm(q)\n",
    "    tol = 1e-17\n",
    "    if qv_n < tol:\n",
    "        return np.array([np.log(q_n),0,0,0])\n",
    "    return np.append(np.log(q_n), qv*np.arccos(qs/q_n)/qv_n)\n",
    "\n",
    "def Quat_Avg(q_set, weights):\n",
    "    weights = np.array(weights).reshape(len(weights),1)\n",
    "    # initial guess as \n",
    "    q_avg = q_set[0]\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    for i in range(1000):\n",
    "        \n",
    "        q_avg_inv = Quat_Inv(q_avg)\n",
    "        q_e_set = np.array([Quat_Multiply(q_avg_inv,q_i) for q_i in q_set])\n",
    "\n",
    "        ev_i = np.array([2*Quat_log(q_e)[1:] for q_e in q_e_set])\n",
    "\n",
    "        ev_i = np.array([ev*(-np.pi+np.mod(np.linalg.norm(ev)+np.pi,2*np.pi))/(np.linalg.norm(ev)) if np.linalg.norm(ev) > epsilon else ev*(-np.pi+np.mod(np.linalg.norm(ev)+np.pi,2*np.pi)) for ev in ev_i])\n",
    "        \n",
    "        ev = np.sum(ev_i*weights,axis=0)\n",
    "\n",
    "        q_avg = Quat_Multiply(q_avg,Quat_exp(np.append(0,ev/2)))\n",
    "    \n",
    "        if np.linalg.norm(ev) < epsilon:\n",
    "            return q_avg\n",
    "        \n",
    "    return q_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UKT Prediction Function\n",
    "\n",
    "def UKF_Euler_Prediction(imu_dict):\n",
    "    \"\"\"\n",
    "    param imu_dict: dictionary that stores the imu data 'vals' and 'data'\n",
    "    \n",
    "    return: numpy array that stores the euler angles predicted by the filter\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization\n",
    "    x_k = np.array([1,0,0,0,0,0,0])#.reshape(7,1)\n",
    "\n",
    "    n = 6\n",
    "    P_k = 0.0001*np.eye(n)\n",
    "    Q = 0.0001*np.eye(n)\n",
    "    R = 0.0001*np.eye(n)\n",
    "    state_vec = []\n",
    "    state_vec.append(x_k)\n",
    "    g = np.array([0,0,0,1])\n",
    "\n",
    "    count = 0\n",
    "    for measurement in imu_dict['vals'].T:\n",
    "        \n",
    "        if count == imu_dict['vals'][3:].shape[1]-1:\n",
    "            break\n",
    "\n",
    "        # Sum the state conv and pre-process noise and cholesky decomp.\n",
    "        S_k = np.linalg.cholesky(P_k + Q)\n",
    "        Wi = np.hstack((np.sqrt(n)*S_k, -np.sqrt(n)*S_k))\n",
    "\n",
    "        # create sigma points Xi_k from Wi_k and S_k and x_k\n",
    "\n",
    "        # get quaternions from first 3 elements of Wi\n",
    "        q_Wi = np.array([Quat_exp(np.append(0,0.5*r)) for r in Wi[:3,:].T])\n",
    "\n",
    "        # get the quaternion part of the sigma points\n",
    "        Xi_q_k = np.array([Quat_Multiply(x_k[:4],q) for q in q_Wi])\n",
    "\n",
    "        # get the angular velocity part of the sigma points\n",
    "        Xi_w_k = np.array([x_k[4:] + W for W in Wi[3:,:].T])\n",
    "\n",
    "        # stack the two parts of the sigma points\n",
    "        Xi_k = np.hstack((Xi_q_k, Xi_w_k))\n",
    "\n",
    "        # add the mean to the sigma points\n",
    "        Xi_k = np.vstack((x_k,Xi_k))\n",
    "\n",
    "        # apply process model to sigma points\n",
    "        # NOTE that noise is not applied in the process model, since noise is applied before process model\n",
    "\n",
    "        delta_t = imu_dict['ts'][0,count+1] - imu_dict['ts'][0,count]\n",
    "\n",
    "        # with delta_q for each sigma point\n",
    "        Yi_q_k = np.array([Quat_Multiply(X[:4],Quat_exp(np.append(0,0.5*delta_t*X[4:]))) for X in Xi_k])\n",
    "\n",
    "        Yi_w_k = Xi_k[:,4:]\n",
    "\n",
    "        # compute the mean of a priori estimate \n",
    "        x_q_k_priori = Quat_Avg(Yi_q_k, np.append(0,np.ones(2*n)/(2*n)))\n",
    "\n",
    "        x_w_k_priori = np.mean(Yi_w_k[1:],axis=0)\n",
    "\n",
    "        Wi_prime_q = np.array([Quat_Multiply(Quat_Inv(x_q_k_priori),q) for q in Yi_q_k]) # subtract quaternion mean by multiplication\n",
    "\n",
    "        Wi_prime_w = Yi_w_k - x_w_k_priori # subtract angular velocity mean\n",
    "\n",
    "        # compute the rotation vector variance from quaternion \n",
    "        Wi_prime_rot = np.array([ 2*Quat_log(q)[1:] for q in Wi_prime_q])\n",
    "\n",
    "        # combine the variance Wi from rot and w\n",
    "        Wi_prime = np.hstack((Wi_prime_rot,Wi_prime_w))\n",
    "\n",
    "        # compute the covariance of Yi\n",
    "        P_k_priori = np.dot(Wi_prime.T, Wi_prime)/(2*n+1)  #cov with equal weights 2*n+1\n",
    "\n",
    "        # construct a new set of sigma points for measurement model\n",
    "\n",
    "        # cholesky decomp. on the priori covariance\n",
    "        S_Y_k = np.linalg.cholesky(P_k_priori)\n",
    "        Wi_m = np.hstack((np.sqrt(n)*S_Y_k, -np.sqrt(n)*S_Y_k))\n",
    "\n",
    "        # create sigma points Yi_m_k from Wi_m and mean \n",
    "\n",
    "        # get quaternions from first 3 elements of Wi\n",
    "        q_Wi_m = np.array([Quat_exp(np.append(0,0.5*r)) for r in Wi_m[:3,:].T])\n",
    "\n",
    "        # get the quaternion part of the new sigma points\n",
    "        Yi_q_m_k = np.array([Quat_Multiply(x_q_k_priori,q) for q in q_Wi_m])\n",
    "\n",
    "        # get the angular velocity part of the new sigma points\n",
    "        Yi_w_m_k = np.array([x_w_k_priori + W for W in Wi_m[3:,:].T])\n",
    "\n",
    "        # add the mean to the sigma points\n",
    "        Yi_q_m_k = np.vstack((x_q_k_priori,Yi_q_m_k))\n",
    "        Yi_w_m_k = np.vstack((x_w_k_priori,Yi_w_m_k))\n",
    "\n",
    "        # project g in world frame to g' with Yi quaternion sigma points\n",
    "        g_prime = np.array([Quat_Multiply(Quat_Inv(Y),Quat_Multiply(g,Y)) for Y in Yi_q_m_k]) #new sigma points\n",
    "\n",
    "        # construct the measurement sigma points with g_prime and Yi_w_k\n",
    "        Zi_k = np.hstack((g_prime[:,1:],Yi_w_m_k)) # new sigma points\n",
    "\n",
    "        # compute mean from the Zi sigma points\n",
    "        Z_k_mean = np.mean(Zi_k[1:],axis=0)\n",
    "\n",
    "        # subtract sigma points Zi from Z_k mean\n",
    "        W_z = Zi_k - Z_k_mean.reshape(1,6)\n",
    "\n",
    "        P_zz = np.dot(W_z.T, W_z)/(2*n+1) # equal weights for all sigma points\n",
    "\n",
    "        # compute covariance of innovation v\n",
    "        P_vv = P_zz + R\n",
    "\n",
    "        # compute the cross correlation matrix of X and Z\n",
    "        P_xz = np.dot(Wi_prime.T, W_z)/(2*n+1)\n",
    "\n",
    "        # compute Kalman Gain\n",
    "        K_k = np.dot(P_xz,np.linalg.inv(P_vv))\n",
    "\n",
    "        # get innovation from the difference between estimated measurements and actual measurements\n",
    "        v_k = measurement - Z_k_mean\n",
    "\n",
    "        # update the state vector mean with Kalman gain\n",
    "        x_q_k = Quat_Multiply(x_q_k_priori,Quat_exp(np.append(0,0.5*np.dot(K_k,v_k)[:3])))\n",
    "        x_w_k = x_w_k_priori + np.dot(K_k,v_k)[3:]\n",
    "        x_k = np.append(x_q_k,x_w_k)\n",
    "\n",
    "        # update the state vector covariance with Kalman gain\n",
    "        P_k = P_k_priori - np.dot(np.dot(K_k,P_vv), K_k.T)\n",
    "\n",
    "        state_vec.append(x_k)\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "    return np.array(state_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTIMIZED stitching\n",
    "ts = tic()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def latlon2cartesian(l): # conversion from Spherical to Cartesian\n",
    "    \"\"\"\n",
    "    function was taken from:\n",
    "    https://stackoverflow.com/questions/1185408/converting-from-longitude-latitude-to-cartesian-coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    r = l[0]\n",
    "    lat = l[1]\n",
    "    lon = l[2]\n",
    "    \n",
    "    x = r * np.cos(lat) * np.cos(lon)\n",
    "    y = r * np.cos(lat) * np.sin(lon)\n",
    "    z = r * np.sin(lat)\n",
    "\n",
    "    #return np.array([x, y, z])\n",
    "    return [x, y, z]\n",
    "\n",
    "def cartesian2latlon(c):\n",
    "    \"\"\"\n",
    "    function was taken from:\n",
    "    https://stackoverflow.com/questions/1185408/converting-from-longitude-latitude-to-cartesian-coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    x = c[0]\n",
    "    y = c[1]\n",
    "    z = c[2]\n",
    "    \n",
    "    #r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    r = 1\n",
    "    lat = np.arcsin(z/r)\n",
    "    lon = np.arctan2(y,x)\n",
    "\n",
    "    #return np.array([r, lat, lon])\n",
    "    return [r, lat, lon]\n",
    "\n",
    "\n",
    "def construct_panorama(camd, imud, q_set):\n",
    "\n",
    "    # in pixels\n",
    "    image_height = camd['cam'].shape[0]\n",
    "    image_width = camd['cam'].shape[1]\n",
    "\n",
    "    # number of pixels for height and width of panorama\n",
    "    panorama_px_height = 180*image_height/45\n",
    "    panorama_px_width = 360*image_width/60\n",
    "    panorama = np.zeros((panorama_px_height,panorama_px_width,3))\n",
    "    \n",
    "    spher2px_ratio_ver = -1*panorama_px_height/np.pi\n",
    "    spher2px_ratio_hor = -1*panorama_px_width/(2*np.pi)\n",
    "\n",
    "    print \"cam_data\"\n",
    "    print camd['cam'].shape\n",
    "\n",
    "    FoV_hor = 60.0*np.pi/180 # rad\n",
    "    FoV_ver = 45.0*np.pi/180  # rad\n",
    "\n",
    "    px2spher_ratio_ver = float(FoV_ver)/image_height\n",
    "    px2spher_ratio_hor = float(FoV_hor)/image_width\n",
    "\n",
    "    # contruct pixel grid\n",
    "    px_grid = np.zeros((image_height,image_width,3))\n",
    "\n",
    "    for i in range(image_height):\n",
    "        for j in range(image_width):\n",
    "            px_grid[i,j] = np.array([-1*(i - image_height/2), -1*(j - image_width/2),1])\n",
    "\n",
    "    px_grid = px_grid.reshape(px_grid.shape[0]*px_grid.shape[1],3)\n",
    "\n",
    "    # everything in one shot, from image pixel coordinates to lat,lon to cartesian in the robot frame\n",
    "    cart_grid = []\n",
    "    for coord in px_grid:\n",
    "        l = [1,coord[0]*px2spher_ratio_ver,coord[1]*px2spher_ratio_hor]\n",
    "        c = latlon2cartesian(l)\n",
    "        cart_grid.append(c)\n",
    "    \n",
    "    cart_grid = np.array(cart_grid)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(camd['cam'].shape[3]):\n",
    "    #for i in range(380,1185):\n",
    "        \n",
    "        # find the closest ts\n",
    "        timee = camd['ts'][0,i] # sample time ts for the image\n",
    "\n",
    "        imud_index = np.argmin(abs(imud['ts'] - timee)) # find the index of vicon ts that is closest to camera ts\n",
    "        q = q_set[imud_index]\n",
    "        rot_mat = quaternion_matrix(q)[:3,:3]\n",
    "        # transform from camera frame to world frame\n",
    "\n",
    "        # everything in one shot, from cartesian to lat,lon to panorama coordinates\n",
    "        panorama_px = []\n",
    "        for carti in cart_grid:\n",
    "            carti_world = np.dot(rot_mat,carti)\n",
    "            latlon_w = cartesian2latlon(carti_world)\n",
    "            panorama_px.append([latlon_w[1]*spher2px_ratio_ver + panorama_px_height/2, latlon_w[2]*spher2px_ratio_hor + panorama_px_width/2])\n",
    "            \n",
    "        panorama_px = np.array(panorama_px)\n",
    "\n",
    "        # put the 1-d panorama pixels back into the image shape\n",
    "        panorama_px_pic = panorama_px.reshape(image_height, image_width,2)\n",
    "\n",
    "        # loop thru the image and put the pixel values on the panorama\n",
    "        for ii in range(image_height):\n",
    "            for jj in range(image_width):\n",
    "                \n",
    "                indexx = panorama_px_pic[ii,jj]\n",
    "                panorama[int(indexx[0]), int(indexx[1]), :] = camd['cam'][ii,jj,:,i]\n",
    "        count += 1\n",
    "    print \"count: \" + str(count)\n",
    "    return panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run UKF on all test sets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for num in range(10,14):\n",
    "    num = 10\n",
    "    ifile = \"testset/imu/imuRaw\" + str(num) + \".p\"\n",
    "    cfile = \"testset/cam/cam\" + str(num) + \".p\"\n",
    "    \n",
    "    # testset directory\n",
    "#     ifile = \"imu/imuRaw\" + str(num) + \".p\"\n",
    "#     cfile = \"cam/cam\" + str(num) + \".p\"\n",
    "    imud = read_data(ifile)\n",
    "    calibrateSensor(imud)\n",
    "    camd = read_data(cfile)\n",
    "\n",
    "    print \"UKF on Training data set \" + str(num)\n",
    "    \n",
    "    ts = tic()\n",
    "    state_vec = UKF_Euler_Prediction(imud)\n",
    "    euler_from_state_vec = np.array([euler_from_quaternion(s[:4]) for s in state_vec])\n",
    "    \n",
    "    toc(ts,\"UKF\")\n",
    "    \n",
    "    # plot the UKF euler angles\n",
    "    roll_from_q_t_set = euler_from_state_vec[:,0]\n",
    "    yaw_from_q_t_set = euler_from_state_vec[:,1]\n",
    "    pitch_from_q_t_set = euler_from_state_vec[:,2]\n",
    "\n",
    "    plt.plot(roll_from_q_t_set, color = 'b', label = 'UKF')\n",
    "    plt.title('roll')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(yaw_from_q_t_set, color = 'b', label = 'UKF')\n",
    "    plt.title('yaw')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(pitch_from_q_t_set, color = 'b', label = 'UKF')\n",
    "    plt.title('pitch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    # stitching\n",
    "    ts = tic()\n",
    "    panorama = construct_panorama(camd, imud, state_vec[:,:4])\n",
    "    toc(ts,\"stitching\")\n",
    "    \n",
    "    plt.imshow(panorama)\n",
    "    plt.title(\"panorama\")\n",
    "    plt.show()\n",
    "    \n",
    "    import cv2\n",
    "    cv2.imwrite('panorama' + str(num) + '.png', panorama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
